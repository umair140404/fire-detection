{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Finetune Models\n",
    "In this notebook, several PyTorch models can be initialized as pretrained models. We can then finetune them based on our own datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import drive if using collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print PyTorch versions and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.11.0+cu113\n",
      "Torchvision Version:  0.12.0+cu113\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models:\n",
    "* resnet\n",
    "* alexnet\n",
    "* vgg\n",
    "* squeezenet\n",
    "* densenet\n",
    "* inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../datasets/final_dataset\"\n",
    "num_classes = 4\n",
    "model_name = \"densenet\"\n",
    "batch_size = 32\n",
    "n_epochs = 10\n",
    "path_to_save = \"../weights/fire_detection_densenet_10epochs.pt\" # .pt file extension\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_path(path):\n",
    "    filename, extension = os.path.splitext(path)\n",
    "    counter = 1\n",
    "\n",
    "    while os.path.exists(path):\n",
    "        path = filename + \"_\" + str(counter) + extension\n",
    "        counter += 1\n",
    "\n",
    "    return path\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, save_path, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 50)\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 50)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                print(\"Training...\")\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                print(\"\\nValidating...\")\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm.notebook.tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4 * loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}%'.format(phase, epoch_loss, epoch_acc * 100))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_epoch = epoch\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f} at epoch: {}'.format(best_acc * 100, epoch))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # save vest model weights\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "    return model, val_acc_history\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(\n",
    "    model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.conv0.weight\n",
      "\t features.norm0.weight\n",
      "\t features.norm0.bias\n",
      "\t features.denseblock1.denselayer1.norm1.weight\n",
      "\t features.denseblock1.denselayer1.norm1.bias\n",
      "\t features.denseblock1.denselayer1.conv1.weight\n",
      "\t features.denseblock1.denselayer1.norm2.weight\n",
      "\t features.denseblock1.denselayer1.norm2.bias\n",
      "\t features.denseblock1.denselayer1.conv2.weight\n",
      "\t features.denseblock1.denselayer2.norm1.weight\n",
      "\t features.denseblock1.denselayer2.norm1.bias\n",
      "\t features.denseblock1.denselayer2.conv1.weight\n",
      "\t features.denseblock1.denselayer2.norm2.weight\n",
      "\t features.denseblock1.denselayer2.norm2.bias\n",
      "\t features.denseblock1.denselayer2.conv2.weight\n",
      "\t features.denseblock1.denselayer3.norm1.weight\n",
      "\t features.denseblock1.denselayer3.norm1.bias\n",
      "\t features.denseblock1.denselayer3.conv1.weight\n",
      "\t features.denseblock1.denselayer3.norm2.weight\n",
      "\t features.denseblock1.denselayer3.norm2.bias\n",
      "\t features.denseblock1.denselayer3.conv2.weight\n",
      "\t features.denseblock1.denselayer4.norm1.weight\n",
      "\t features.denseblock1.denselayer4.norm1.bias\n",
      "\t features.denseblock1.denselayer4.conv1.weight\n",
      "\t features.denseblock1.denselayer4.norm2.weight\n",
      "\t features.denseblock1.denselayer4.norm2.bias\n",
      "\t features.denseblock1.denselayer4.conv2.weight\n",
      "\t features.denseblock1.denselayer5.norm1.weight\n",
      "\t features.denseblock1.denselayer5.norm1.bias\n",
      "\t features.denseblock1.denselayer5.conv1.weight\n",
      "\t features.denseblock1.denselayer5.norm2.weight\n",
      "\t features.denseblock1.denselayer5.norm2.bias\n",
      "\t features.denseblock1.denselayer5.conv2.weight\n",
      "\t features.denseblock1.denselayer6.norm1.weight\n",
      "\t features.denseblock1.denselayer6.norm1.bias\n",
      "\t features.denseblock1.denselayer6.conv1.weight\n",
      "\t features.denseblock1.denselayer6.norm2.weight\n",
      "\t features.denseblock1.denselayer6.norm2.bias\n",
      "\t features.denseblock1.denselayer6.conv2.weight\n",
      "\t features.transition1.norm.weight\n",
      "\t features.transition1.norm.bias\n",
      "\t features.transition1.conv.weight\n",
      "\t features.denseblock2.denselayer1.norm1.weight\n",
      "\t features.denseblock2.denselayer1.norm1.bias\n",
      "\t features.denseblock2.denselayer1.conv1.weight\n",
      "\t features.denseblock2.denselayer1.norm2.weight\n",
      "\t features.denseblock2.denselayer1.norm2.bias\n",
      "\t features.denseblock2.denselayer1.conv2.weight\n",
      "\t features.denseblock2.denselayer2.norm1.weight\n",
      "\t features.denseblock2.denselayer2.norm1.bias\n",
      "\t features.denseblock2.denselayer2.conv1.weight\n",
      "\t features.denseblock2.denselayer2.norm2.weight\n",
      "\t features.denseblock2.denselayer2.norm2.bias\n",
      "\t features.denseblock2.denselayer2.conv2.weight\n",
      "\t features.denseblock2.denselayer3.norm1.weight\n",
      "\t features.denseblock2.denselayer3.norm1.bias\n",
      "\t features.denseblock2.denselayer3.conv1.weight\n",
      "\t features.denseblock2.denselayer3.norm2.weight\n",
      "\t features.denseblock2.denselayer3.norm2.bias\n",
      "\t features.denseblock2.denselayer3.conv2.weight\n",
      "\t features.denseblock2.denselayer4.norm1.weight\n",
      "\t features.denseblock2.denselayer4.norm1.bias\n",
      "\t features.denseblock2.denselayer4.conv1.weight\n",
      "\t features.denseblock2.denselayer4.norm2.weight\n",
      "\t features.denseblock2.denselayer4.norm2.bias\n",
      "\t features.denseblock2.denselayer4.conv2.weight\n",
      "\t features.denseblock2.denselayer5.norm1.weight\n",
      "\t features.denseblock2.denselayer5.norm1.bias\n",
      "\t features.denseblock2.denselayer5.conv1.weight\n",
      "\t features.denseblock2.denselayer5.norm2.weight\n",
      "\t features.denseblock2.denselayer5.norm2.bias\n",
      "\t features.denseblock2.denselayer5.conv2.weight\n",
      "\t features.denseblock2.denselayer6.norm1.weight\n",
      "\t features.denseblock2.denselayer6.norm1.bias\n",
      "\t features.denseblock2.denselayer6.conv1.weight\n",
      "\t features.denseblock2.denselayer6.norm2.weight\n",
      "\t features.denseblock2.denselayer6.norm2.bias\n",
      "\t features.denseblock2.denselayer6.conv2.weight\n",
      "\t features.denseblock2.denselayer7.norm1.weight\n",
      "\t features.denseblock2.denselayer7.norm1.bias\n",
      "\t features.denseblock2.denselayer7.conv1.weight\n",
      "\t features.denseblock2.denselayer7.norm2.weight\n",
      "\t features.denseblock2.denselayer7.norm2.bias\n",
      "\t features.denseblock2.denselayer7.conv2.weight\n",
      "\t features.denseblock2.denselayer8.norm1.weight\n",
      "\t features.denseblock2.denselayer8.norm1.bias\n",
      "\t features.denseblock2.denselayer8.conv1.weight\n",
      "\t features.denseblock2.denselayer8.norm2.weight\n",
      "\t features.denseblock2.denselayer8.norm2.bias\n",
      "\t features.denseblock2.denselayer8.conv2.weight\n",
      "\t features.denseblock2.denselayer9.norm1.weight\n",
      "\t features.denseblock2.denselayer9.norm1.bias\n",
      "\t features.denseblock2.denselayer9.conv1.weight\n",
      "\t features.denseblock2.denselayer9.norm2.weight\n",
      "\t features.denseblock2.denselayer9.norm2.bias\n",
      "\t features.denseblock2.denselayer9.conv2.weight\n",
      "\t features.denseblock2.denselayer10.norm1.weight\n",
      "\t features.denseblock2.denselayer10.norm1.bias\n",
      "\t features.denseblock2.denselayer10.conv1.weight\n",
      "\t features.denseblock2.denselayer10.norm2.weight\n",
      "\t features.denseblock2.denselayer10.norm2.bias\n",
      "\t features.denseblock2.denselayer10.conv2.weight\n",
      "\t features.denseblock2.denselayer11.norm1.weight\n",
      "\t features.denseblock2.denselayer11.norm1.bias\n",
      "\t features.denseblock2.denselayer11.conv1.weight\n",
      "\t features.denseblock2.denselayer11.norm2.weight\n",
      "\t features.denseblock2.denselayer11.norm2.bias\n",
      "\t features.denseblock2.denselayer11.conv2.weight\n",
      "\t features.denseblock2.denselayer12.norm1.weight\n",
      "\t features.denseblock2.denselayer12.norm1.bias\n",
      "\t features.denseblock2.denselayer12.conv1.weight\n",
      "\t features.denseblock2.denselayer12.norm2.weight\n",
      "\t features.denseblock2.denselayer12.norm2.bias\n",
      "\t features.denseblock2.denselayer12.conv2.weight\n",
      "\t features.transition2.norm.weight\n",
      "\t features.transition2.norm.bias\n",
      "\t features.transition2.conv.weight\n",
      "\t features.denseblock3.denselayer1.norm1.weight\n",
      "\t features.denseblock3.denselayer1.norm1.bias\n",
      "\t features.denseblock3.denselayer1.conv1.weight\n",
      "\t features.denseblock3.denselayer1.norm2.weight\n",
      "\t features.denseblock3.denselayer1.norm2.bias\n",
      "\t features.denseblock3.denselayer1.conv2.weight\n",
      "\t features.denseblock3.denselayer2.norm1.weight\n",
      "\t features.denseblock3.denselayer2.norm1.bias\n",
      "\t features.denseblock3.denselayer2.conv1.weight\n",
      "\t features.denseblock3.denselayer2.norm2.weight\n",
      "\t features.denseblock3.denselayer2.norm2.bias\n",
      "\t features.denseblock3.denselayer2.conv2.weight\n",
      "\t features.denseblock3.denselayer3.norm1.weight\n",
      "\t features.denseblock3.denselayer3.norm1.bias\n",
      "\t features.denseblock3.denselayer3.conv1.weight\n",
      "\t features.denseblock3.denselayer3.norm2.weight\n",
      "\t features.denseblock3.denselayer3.norm2.bias\n",
      "\t features.denseblock3.denselayer3.conv2.weight\n",
      "\t features.denseblock3.denselayer4.norm1.weight\n",
      "\t features.denseblock3.denselayer4.norm1.bias\n",
      "\t features.denseblock3.denselayer4.conv1.weight\n",
      "\t features.denseblock3.denselayer4.norm2.weight\n",
      "\t features.denseblock3.denselayer4.norm2.bias\n",
      "\t features.denseblock3.denselayer4.conv2.weight\n",
      "\t features.denseblock3.denselayer5.norm1.weight\n",
      "\t features.denseblock3.denselayer5.norm1.bias\n",
      "\t features.denseblock3.denselayer5.conv1.weight\n",
      "\t features.denseblock3.denselayer5.norm2.weight\n",
      "\t features.denseblock3.denselayer5.norm2.bias\n",
      "\t features.denseblock3.denselayer5.conv2.weight\n",
      "\t features.denseblock3.denselayer6.norm1.weight\n",
      "\t features.denseblock3.denselayer6.norm1.bias\n",
      "\t features.denseblock3.denselayer6.conv1.weight\n",
      "\t features.denseblock3.denselayer6.norm2.weight\n",
      "\t features.denseblock3.denselayer6.norm2.bias\n",
      "\t features.denseblock3.denselayer6.conv2.weight\n",
      "\t features.denseblock3.denselayer7.norm1.weight\n",
      "\t features.denseblock3.denselayer7.norm1.bias\n",
      "\t features.denseblock3.denselayer7.conv1.weight\n",
      "\t features.denseblock3.denselayer7.norm2.weight\n",
      "\t features.denseblock3.denselayer7.norm2.bias\n",
      "\t features.denseblock3.denselayer7.conv2.weight\n",
      "\t features.denseblock3.denselayer8.norm1.weight\n",
      "\t features.denseblock3.denselayer8.norm1.bias\n",
      "\t features.denseblock3.denselayer8.conv1.weight\n",
      "\t features.denseblock3.denselayer8.norm2.weight\n",
      "\t features.denseblock3.denselayer8.norm2.bias\n",
      "\t features.denseblock3.denselayer8.conv2.weight\n",
      "\t features.denseblock3.denselayer9.norm1.weight\n",
      "\t features.denseblock3.denselayer9.norm1.bias\n",
      "\t features.denseblock3.denselayer9.conv1.weight\n",
      "\t features.denseblock3.denselayer9.norm2.weight\n",
      "\t features.denseblock3.denselayer9.norm2.bias\n",
      "\t features.denseblock3.denselayer9.conv2.weight\n",
      "\t features.denseblock3.denselayer10.norm1.weight\n",
      "\t features.denseblock3.denselayer10.norm1.bias\n",
      "\t features.denseblock3.denselayer10.conv1.weight\n",
      "\t features.denseblock3.denselayer10.norm2.weight\n",
      "\t features.denseblock3.denselayer10.norm2.bias\n",
      "\t features.denseblock3.denselayer10.conv2.weight\n",
      "\t features.denseblock3.denselayer11.norm1.weight\n",
      "\t features.denseblock3.denselayer11.norm1.bias\n",
      "\t features.denseblock3.denselayer11.conv1.weight\n",
      "\t features.denseblock3.denselayer11.norm2.weight\n",
      "\t features.denseblock3.denselayer11.norm2.bias\n",
      "\t features.denseblock3.denselayer11.conv2.weight\n",
      "\t features.denseblock3.denselayer12.norm1.weight\n",
      "\t features.denseblock3.denselayer12.norm1.bias\n",
      "\t features.denseblock3.denselayer12.conv1.weight\n",
      "\t features.denseblock3.denselayer12.norm2.weight\n",
      "\t features.denseblock3.denselayer12.norm2.bias\n",
      "\t features.denseblock3.denselayer12.conv2.weight\n",
      "\t features.denseblock3.denselayer13.norm1.weight\n",
      "\t features.denseblock3.denselayer13.norm1.bias\n",
      "\t features.denseblock3.denselayer13.conv1.weight\n",
      "\t features.denseblock3.denselayer13.norm2.weight\n",
      "\t features.denseblock3.denselayer13.norm2.bias\n",
      "\t features.denseblock3.denselayer13.conv2.weight\n",
      "\t features.denseblock3.denselayer14.norm1.weight\n",
      "\t features.denseblock3.denselayer14.norm1.bias\n",
      "\t features.denseblock3.denselayer14.conv1.weight\n",
      "\t features.denseblock3.denselayer14.norm2.weight\n",
      "\t features.denseblock3.denselayer14.norm2.bias\n",
      "\t features.denseblock3.denselayer14.conv2.weight\n",
      "\t features.denseblock3.denselayer15.norm1.weight\n",
      "\t features.denseblock3.denselayer15.norm1.bias\n",
      "\t features.denseblock3.denselayer15.conv1.weight\n",
      "\t features.denseblock3.denselayer15.norm2.weight\n",
      "\t features.denseblock3.denselayer15.norm2.bias\n",
      "\t features.denseblock3.denselayer15.conv2.weight\n",
      "\t features.denseblock3.denselayer16.norm1.weight\n",
      "\t features.denseblock3.denselayer16.norm1.bias\n",
      "\t features.denseblock3.denselayer16.conv1.weight\n",
      "\t features.denseblock3.denselayer16.norm2.weight\n",
      "\t features.denseblock3.denselayer16.norm2.bias\n",
      "\t features.denseblock3.denselayer16.conv2.weight\n",
      "\t features.denseblock3.denselayer17.norm1.weight\n",
      "\t features.denseblock3.denselayer17.norm1.bias\n",
      "\t features.denseblock3.denselayer17.conv1.weight\n",
      "\t features.denseblock3.denselayer17.norm2.weight\n",
      "\t features.denseblock3.denselayer17.norm2.bias\n",
      "\t features.denseblock3.denselayer17.conv2.weight\n",
      "\t features.denseblock3.denselayer18.norm1.weight\n",
      "\t features.denseblock3.denselayer18.norm1.bias\n",
      "\t features.denseblock3.denselayer18.conv1.weight\n",
      "\t features.denseblock3.denselayer18.norm2.weight\n",
      "\t features.denseblock3.denselayer18.norm2.bias\n",
      "\t features.denseblock3.denselayer18.conv2.weight\n",
      "\t features.denseblock3.denselayer19.norm1.weight\n",
      "\t features.denseblock3.denselayer19.norm1.bias\n",
      "\t features.denseblock3.denselayer19.conv1.weight\n",
      "\t features.denseblock3.denselayer19.norm2.weight\n",
      "\t features.denseblock3.denselayer19.norm2.bias\n",
      "\t features.denseblock3.denselayer19.conv2.weight\n",
      "\t features.denseblock3.denselayer20.norm1.weight\n",
      "\t features.denseblock3.denselayer20.norm1.bias\n",
      "\t features.denseblock3.denselayer20.conv1.weight\n",
      "\t features.denseblock3.denselayer20.norm2.weight\n",
      "\t features.denseblock3.denselayer20.norm2.bias\n",
      "\t features.denseblock3.denselayer20.conv2.weight\n",
      "\t features.denseblock3.denselayer21.norm1.weight\n",
      "\t features.denseblock3.denselayer21.norm1.bias\n",
      "\t features.denseblock3.denselayer21.conv1.weight\n",
      "\t features.denseblock3.denselayer21.norm2.weight\n",
      "\t features.denseblock3.denselayer21.norm2.bias\n",
      "\t features.denseblock3.denselayer21.conv2.weight\n",
      "\t features.denseblock3.denselayer22.norm1.weight\n",
      "\t features.denseblock3.denselayer22.norm1.bias\n",
      "\t features.denseblock3.denselayer22.conv1.weight\n",
      "\t features.denseblock3.denselayer22.norm2.weight\n",
      "\t features.denseblock3.denselayer22.norm2.bias\n",
      "\t features.denseblock3.denselayer22.conv2.weight\n",
      "\t features.denseblock3.denselayer23.norm1.weight\n",
      "\t features.denseblock3.denselayer23.norm1.bias\n",
      "\t features.denseblock3.denselayer23.conv1.weight\n",
      "\t features.denseblock3.denselayer23.norm2.weight\n",
      "\t features.denseblock3.denselayer23.norm2.bias\n",
      "\t features.denseblock3.denselayer23.conv2.weight\n",
      "\t features.denseblock3.denselayer24.norm1.weight\n",
      "\t features.denseblock3.denselayer24.norm1.bias\n",
      "\t features.denseblock3.denselayer24.conv1.weight\n",
      "\t features.denseblock3.denselayer24.norm2.weight\n",
      "\t features.denseblock3.denselayer24.norm2.bias\n",
      "\t features.denseblock3.denselayer24.conv2.weight\n",
      "\t features.transition3.norm.weight\n",
      "\t features.transition3.norm.bias\n",
      "\t features.transition3.conv.weight\n",
      "\t features.denseblock4.denselayer1.norm1.weight\n",
      "\t features.denseblock4.denselayer1.norm1.bias\n",
      "\t features.denseblock4.denselayer1.conv1.weight\n",
      "\t features.denseblock4.denselayer1.norm2.weight\n",
      "\t features.denseblock4.denselayer1.norm2.bias\n",
      "\t features.denseblock4.denselayer1.conv2.weight\n",
      "\t features.denseblock4.denselayer2.norm1.weight\n",
      "\t features.denseblock4.denselayer2.norm1.bias\n",
      "\t features.denseblock4.denselayer2.conv1.weight\n",
      "\t features.denseblock4.denselayer2.norm2.weight\n",
      "\t features.denseblock4.denselayer2.norm2.bias\n",
      "\t features.denseblock4.denselayer2.conv2.weight\n",
      "\t features.denseblock4.denselayer3.norm1.weight\n",
      "\t features.denseblock4.denselayer3.norm1.bias\n",
      "\t features.denseblock4.denselayer3.conv1.weight\n",
      "\t features.denseblock4.denselayer3.norm2.weight\n",
      "\t features.denseblock4.denselayer3.norm2.bias\n",
      "\t features.denseblock4.denselayer3.conv2.weight\n",
      "\t features.denseblock4.denselayer4.norm1.weight\n",
      "\t features.denseblock4.denselayer4.norm1.bias\n",
      "\t features.denseblock4.denselayer4.conv1.weight\n",
      "\t features.denseblock4.denselayer4.norm2.weight\n",
      "\t features.denseblock4.denselayer4.norm2.bias\n",
      "\t features.denseblock4.denselayer4.conv2.weight\n",
      "\t features.denseblock4.denselayer5.norm1.weight\n",
      "\t features.denseblock4.denselayer5.norm1.bias\n",
      "\t features.denseblock4.denselayer5.conv1.weight\n",
      "\t features.denseblock4.denselayer5.norm2.weight\n",
      "\t features.denseblock4.denselayer5.norm2.bias\n",
      "\t features.denseblock4.denselayer5.conv2.weight\n",
      "\t features.denseblock4.denselayer6.norm1.weight\n",
      "\t features.denseblock4.denselayer6.norm1.bias\n",
      "\t features.denseblock4.denselayer6.conv1.weight\n",
      "\t features.denseblock4.denselayer6.norm2.weight\n",
      "\t features.denseblock4.denselayer6.norm2.bias\n",
      "\t features.denseblock4.denselayer6.conv2.weight\n",
      "\t features.denseblock4.denselayer7.norm1.weight\n",
      "\t features.denseblock4.denselayer7.norm1.bias\n",
      "\t features.denseblock4.denselayer7.conv1.weight\n",
      "\t features.denseblock4.denselayer7.norm2.weight\n",
      "\t features.denseblock4.denselayer7.norm2.bias\n",
      "\t features.denseblock4.denselayer7.conv2.weight\n",
      "\t features.denseblock4.denselayer8.norm1.weight\n",
      "\t features.denseblock4.denselayer8.norm1.bias\n",
      "\t features.denseblock4.denselayer8.conv1.weight\n",
      "\t features.denseblock4.denselayer8.norm2.weight\n",
      "\t features.denseblock4.denselayer8.norm2.bias\n",
      "\t features.denseblock4.denselayer8.conv2.weight\n",
      "\t features.denseblock4.denselayer9.norm1.weight\n",
      "\t features.denseblock4.denselayer9.norm1.bias\n",
      "\t features.denseblock4.denselayer9.conv1.weight\n",
      "\t features.denseblock4.denselayer9.norm2.weight\n",
      "\t features.denseblock4.denselayer9.norm2.bias\n",
      "\t features.denseblock4.denselayer9.conv2.weight\n",
      "\t features.denseblock4.denselayer10.norm1.weight\n",
      "\t features.denseblock4.denselayer10.norm1.bias\n",
      "\t features.denseblock4.denselayer10.conv1.weight\n",
      "\t features.denseblock4.denselayer10.norm2.weight\n",
      "\t features.denseblock4.denselayer10.norm2.bias\n",
      "\t features.denseblock4.denselayer10.conv2.weight\n",
      "\t features.denseblock4.denselayer11.norm1.weight\n",
      "\t features.denseblock4.denselayer11.norm1.bias\n",
      "\t features.denseblock4.denselayer11.conv1.weight\n",
      "\t features.denseblock4.denselayer11.norm2.weight\n",
      "\t features.denseblock4.denselayer11.norm2.bias\n",
      "\t features.denseblock4.denselayer11.conv2.weight\n",
      "\t features.denseblock4.denselayer12.norm1.weight\n",
      "\t features.denseblock4.denselayer12.norm1.bias\n",
      "\t features.denseblock4.denselayer12.conv1.weight\n",
      "\t features.denseblock4.denselayer12.norm2.weight\n",
      "\t features.denseblock4.denselayer12.norm2.bias\n",
      "\t features.denseblock4.denselayer12.conv2.weight\n",
      "\t features.denseblock4.denselayer13.norm1.weight\n",
      "\t features.denseblock4.denselayer13.norm1.bias\n",
      "\t features.denseblock4.denselayer13.conv1.weight\n",
      "\t features.denseblock4.denselayer13.norm2.weight\n",
      "\t features.denseblock4.denselayer13.norm2.bias\n",
      "\t features.denseblock4.denselayer13.conv2.weight\n",
      "\t features.denseblock4.denselayer14.norm1.weight\n",
      "\t features.denseblock4.denselayer14.norm1.bias\n",
      "\t features.denseblock4.denselayer14.conv1.weight\n",
      "\t features.denseblock4.denselayer14.norm2.weight\n",
      "\t features.denseblock4.denselayer14.norm2.bias\n",
      "\t features.denseblock4.denselayer14.conv2.weight\n",
      "\t features.denseblock4.denselayer15.norm1.weight\n",
      "\t features.denseblock4.denselayer15.norm1.bias\n",
      "\t features.denseblock4.denselayer15.conv1.weight\n",
      "\t features.denseblock4.denselayer15.norm2.weight\n",
      "\t features.denseblock4.denselayer15.norm2.bias\n",
      "\t features.denseblock4.denselayer15.conv2.weight\n",
      "\t features.denseblock4.denselayer16.norm1.weight\n",
      "\t features.denseblock4.denselayer16.norm1.bias\n",
      "\t features.denseblock4.denselayer16.conv1.weight\n",
      "\t features.denseblock4.denselayer16.norm2.weight\n",
      "\t features.denseblock4.denselayer16.norm2.bias\n",
      "\t features.denseblock4.denselayer16.conv2.weight\n",
      "\t features.norm5.weight\n",
      "\t features.norm5.bias\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 1/1\n",
      "--------------------------------------------------\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2582c37c3a3494fa17f0f15bd5a24a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4263 Acc: 85.8403%\n",
      "\n",
      "Validating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84ba48043d649a89de239718bb9a295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0804 Acc: 97.2519%\n",
      "\n",
      "Training complete in 1m 30s\n",
      "Best val Acc: 97.251908 at epoch: 0\n",
      "Model saved to ../weights/fire_detection_densenet_10epochs_1.pt\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, unique_path(path_to_save), num_epochs=n_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "final_hist = []\n",
    "\n",
    "final_hist = [h.cpu().numpy() for h in hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Epochs\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(0, n_epochs), final_hist,label=\"finetuned\")\n",
    "plt.ylim((0,1.))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d610c201457c5e52daae9a51368c34c2032b2a44369978e02d46e83d53bdf74b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
